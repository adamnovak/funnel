/*
  Task Execution Service

  ## Executive Summary The Task Execution Service (TES) API is a standardized schema and API for describing and executing batch execution tasks. A task defines a set of input files, a set of containers and commands to run, a set of output files and some other logging and metadata.  TES servers accept task documents and execute them asynchronously on available compute resources. A TES server could be built on top of a traditional HPC queuing system, such as Grid Engine, Slurm or cloud style compute systems such as AWS Batch or Kubernetes. ## Introduction This document describes the TES API and provides details on the specific endpoints, request formats, and responses. It is intended to provide key information for developers of TES-compatible services as well as clients that will call these TES services. Use cases include:    - Deploying existing workflow engines on new infrastructure. Workflow engines   such as CWL-Tes and Cromwell have extentions for using TES. This will allow   a system engineer to deploy them onto a new infrastructure using a job scheduling   system not previously supported by the engine.    - Developing a custom workflow management system. This API provides a common   interface to asynchronous batch processing capabilities. A developer can write   new tools against this interface and expect them to work using a variety of   backend solutions that all support the same specification.   ## Standards The TES API specification is written in OpenAPI and embodies a RESTful service philosophy. It uses JSON in requests and responses and standard HTTP/HTTPS for information transport. HTTPS should be used rather than plain HTTP except for testing or internal-only purposes. ### Authentication and Authorization Is is envisaged that most TES API instances will require users to authenticate to use the endpoints. However, the decision if authentication is required should be taken by TES API implementers.  If authentication is required, we recommend that TES implementations use an OAuth2  bearer token, although they can choose other mechanisms if appropriate.  Checking that a user is authorized to submit TES requests is a responsibility of TES implementations. ### CORS If TES API implementation is to be used by another website or domain it must implement Cross Origin Resource Sharing (CORS). Please refer to https://w3id.org/ga4gh/product-approval-support/cors for more information about GA4GHâ€™s recommendations and how to implement CORS. 

  The version of the OpenAPI document: 1.0.0

  Generated by OpenAPI Generator: https://openapi-generator.tech
*/

syntax = "proto3";

option go_package = "github.com/ohsu-comp-bio/funnel/tes/proto/models";
package models;

import public "models/tes_executor.proto";
import public "models/tes_input.proto";
import public "models/tes_output.proto";
import public "models/tes_resources.proto";
import public "models/tes_state.proto";
import public "models/tes_task_log.proto";

message TesTask {

  // Task identifier assigned by the server.
  string id = 3355;

  TesState state = 109757585;

  // User-provided task name.
  string name = 3373707;

  // Optional user-provided description of task for documentation purposes.
  string description = 113933319;

  // Input files that will be used by the task. Inputs will be downloaded and mounted into the executor container as defined by the task request document.
  repeated TesInput inputs = 110124569;

  // Output files. Outputs will be uploaded from the executor container to long-term storage.
  repeated TesOutput outputs = 32372848;

  TesResources resources = 372457950;

  // An array of executors to be run. Each of the executors will run one at a time sequentially. Each executor is a different command that will be run, and each can utilize a different docker image. But each of the executors will see the same mapped inputs and volumes that are declared in the parent CreateTask message.  Execution stops on the first error.
  repeated TesExecutor executors = 17227266;

  // Volumes are directories which may be used to share data between Executors. Volumes are initialized as empty directories by the system when the task starts and are mounted at the same path in each Executor.  For example, given a volume defined at `/vol/A`, executor 1 may write a file to `/vol/A/exec1.out.txt`, then executor 2 may read from that file.  (Essentially, this translates to a `docker run -v` flag where the container path is the same for each executor).
  repeated string volumes = 95550618;

  // A key-value map of arbitrary tags. These can be used to store meta-data and annotations about a task. Example: ``` {   \"tags\" : {       \"WORKFLOW_ID\" : \"cwl-01234\",       \"PROJECT_GROUP\" : \"alice-lab\"   } } ```
  map<string, string> tags = 3552281;

  // Task logging information. Normally, this will contain only one entry, but in the case where a task fails and is retried, an entry will be appended to this list.
  repeated TesTaskLog logs = 3327407;

  // Date + time the task was created, in RFC 3339 format. This is set by the system, not the client.
  string creationUnderscoretime = 113422662;

}
